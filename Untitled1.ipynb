{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a861a711",
   "metadata": {},
   "source": [
    "### Variable Selection Using Random Forests\n",
    "\n",
    "Another variable selection method with promising variance reduction uses **random  forests** (RF). RF are non-parametric and – in the terminology of machine learning – belong to the family of ensemble methods. Proposed by Breiman (2001), the defining feature of the RF algorithm is that it aggregates *decorrelated* decision trees, which is particularly effective for the reduction in variance. Unlike the Lasso estimators, RF does not naturally perform variable selection. However, several procedures exploiting variable importance scores exist (for examples, see Guyon and Elisseeff, 2003; Kohavi and John, 1997).  In this paper we consider the stepwise ascending variable introduction strategy developed by Genuer et al. (2010) and implemented in the `VSURF` package available on the R-CRAN library.\n",
    "\n",
    "Decision trees are built using recursive binary splits to minimize the residual sum of squares, given by\n",
    "\n",
    "$ \\sum^{J}_{j=1} \\sum_{I \\in R_j} (y_i - \\hat{y_{R_j}}) ^2$\n",
    "\n",
    "where $\\hat{y_{R_j}}$ is the mean response for the training observation within the $j$th box.  However, even though pruning can be used to stop overfitting decision trees – a single decision tree usually only has poor predictive performance. The reason is that while their bias is low, their prediction accuracy suffers from a very high variance. Still, since aggregation reduces variance, aggregating the results of many bootstrapped trees allows us to trade-in some bias for a significant reduction in variance. This is fundamental principle of “bagging”: $B$ bootstrapped training samples are generated and for each sample an unpruned tree is grown, causing it to have very low bias. The resulting predictions are then averaged, or in the case of a classification problem, a majority vote is taken. Breiman’s seminal contribution was then the proposition of a simple algorithm to **decorrelate** individual trees – which makes the bias-variance trade-off significantly more efficient (Breiman, 2001; for a more general introduction, see James et al., 2013). Bagged trees can exhibit significant correlation if, for example, there are a few very strong predictors which all trees will want to use. If all trees are very similar, averaging them will not lead to a substantial decrease in variance over a single tree (James et al., 2013, p. 320). Breiman suggested that for each bagged tree, at each node the available predictors are limited to a *random sample $m$ of all predictors*. Note that if $m=p$, this simply reduces to the standard “bagging” procedure. \n",
    "\n",
    "In R, the popular `randomForest` package implements  Breiman’s algorithm, the two tuning parameters `ntree` and `mytry` respond to the number of total trees grown and the size of the predictor subset that is available at each split. In practice we typically choose $m \\approx \\sqrt{p}$, but inparticular if correlation among the predictors is strong, smaller values of `mytry` can have positive impact on predictive performance (for a comparison, see James et al., 2013).\n",
    "\n",
    "Now, as mentioned above, the second ingredient for variable selection using random forests is typically the metric of **variable importance** (VI). There exist a multiplicity of VI indicators, however, in the random forests framework, the most prominent VI score are so-called “permutation indices” (Genuer et al., 2010): this is the increase in mean Mean-Squared-Error (MSE) of a tree in the forest when the observed values of this variable are randomly permuted in the Out-of-Bag (OOB) samples. Other types of scores, for example, make use of variance decomposition or, in classification, to nude purity. For a comparison of the behaviour of different VI scores, refer to Strobl et al. (2008) and Archer and Kimes (2008). Importantly, analysing the behaviour of the permutation-based MSE reduction VI sore, Genuer et al. (2010) find that the **importance ranking**  of predictors is extremely stable. In fact, this is the key property used in the two-step variable selection procedure.\n",
    "\n",
    "The strategy designed by Genuer et al. (2010) distinguishes between two goals: interpretation and prediction. The first step of variable importance ranking is common for both goals, but in the second step they differ in the level of aggressiveness with which they eliminate variables. As the authors concede, the distinction can seem artificial at times since i) both methodologies use prediction accuracy as their performance criterion and ii) the “interpretation” set is designed to be **less** parsimonious than the “prediction” set of variables (Genuer et al., 2015). Note that in the simulation only the “prediction” set is used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
