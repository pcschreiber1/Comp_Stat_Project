---
title: "R Notebook"
output:
  html_notebook: default
  pdf_document: default
---



```{r}
#Installing packages#
#install.packages("parallel")
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.
```{r}
library(MASS) 
library(stats)
library(Matrix)
library(parallel)
library(glmnet) #for LASSO
library(VSURF)#for RF
library(ggplot2) #for plotting
library(dplyr) #for plotting
library(cowplot) #for plotting
```


```{r}
#Import auxiliary functions
source("auxiliary_functions.R", local=FALSE)
```
```{r}
set.seed(456)
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
beta = beta_1(p=100,s=5)
df <- simulate(n=100, p=100, rho=0.5, beta=beta, SNR = 1)$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe

cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
plot(cv.out) # Draw plot of training MSE as a function of lambda
lam = cv.out$lambda.1se # Select more conservative lambda for variable selection


lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
```


```{r}

beta = beta_2(p=50,s=5)
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = 1)$df
result = RF_VSURF(data=df, beta=beta)

```






```{r}
RF_VSURF <- function(data, #data frame - dependent variable first
                     beta #true coefficients
){
  #--------------------------
  # Uses VSURF prediction under parallelization and
  # returns number of correctly identified  significant variables.
  # Mytree and ntree are set to default
  # ------------------------- 
  x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
  y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
  
  defaultW <- getOption("warn")  #Turn off warning messages
  options(warn = -1) 
  

  #Variable Selection using Random Forest
  model.vsurf <- VSURF(x=x, y=y, parallel = TRUE , ncores= 4)
  
  options(warn = defaultW) #re-enable warning messages

  #---------------------
  # Retention Frequency
  #---------------------
  #Create boolian vector of selected coefficients
  loc = model.vsurf$varselect.pred # location of significant coefficients
  estim_var = rep(0, length(beta)) #create zero vector of correct length
  estim_var[loc] = 1 #populate zero vector
  
  retention = var_retention(estim_var, beta) #counts only significant variables
  identification = var_identification(estim_var, beta) #counts all vars

  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(estim_var, beta) #count nonzero vars
  
  #---------------------
  # OOB error
  #---------------------
  OOB_error = min(model.vsurf$err.pred) # VSURF returns a vector, final element is (minimal) OOB error and includes all !prediction! variables
  
  result = list("retention" = retention, "identification" = identification, "OOB_error" = OOB_error, "nonzero" = nonzero)
  
  return(result)
}
  

```








```{r}
cv.lasso_2 <- function(data, #data frame - dependent variable first
                     beta # true coefficients
){
  #--------------------------
  # Uses 10 fold CV and uses best prediciton lambda
  # as estimate for variable selection
  # -------------------------
  x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
  y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
  
  cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
  #lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
  lam = cv.out$lambda.min
  
  #---------------------
  # Retention Frequency
  #---------------------
  lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
  retention = var_retention(lasso_coef, beta) #counts significant vars
  identification = var_identification(lasso_coef, beta) #counts all vars

  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
  
  #---------------------
  # MSE
  #---------------------
  mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se]
  
  
  results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
  return(results)
}
```


```{r}
cv.relaxed_lasso <- function(data, #data frame - dependent variable first
                     beta # true coefficients
){
  #--------------------------
  # Uses 10 fold CV and uses lambda
  # and gamma minimizing prediction error
  # for variable selection
  # -------------------------
  x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
  y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
  
  cv.out = cv.glmnet(x, y,intercept=FALSE, relax=TRUE) # Fit lasso model on training data

  #---------------------
  # Retention Frequency
  #---------------------
  lasso_coef = predict(cv.out, type = "coefficients", s = "lambda.min", gamma = "gamma.min")#"gamma.min") # Display coefficients using lambda chosen by CV
  retention = var_retention(lasso_coef, beta) #counts significant vars
  identification = var_identification(lasso_coef, beta) #counts all vars

  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
  
  #---------------------
  # MSE
  #---------------------
  mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se] # which gamma value is this?
  
  
  results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
  return(results)
  
}
```





```{r}
#--------------------------------
# Simulation 1
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim1.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)


```

```{r}
sim1 <- read.csv("sim1.csv", header=TRUE)
View(sim1)
```



```{r}
df <- sim1 %>% 
  na_if(Inf) %>%
  group_by(SNR, Method) %>%  
  summarize(Mean_Ret = mean(Retention, na.rm=TRUE),
            Mean_Zero = mean(Nonzero, na.rm=TRUE),
            Mean_Pred = mean(Prediction, na.rm=TRUE))

snr.breaks = round(exp(seq(from=min(log(sim1$SNR)),
                           to=max(log(sim1$SNR)),length=4)),2)

ggplot(data=df, aes(x=SNR, y=Mean_Ret, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Retention") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Zero, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Number nonzero coefficients") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Pred, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Prediction Error") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)
```






```{r}
#--------------------------------
# Simulation 2
#--------------------------------

start_time <- Sys.time()

# Number of simulations
n_sim = 30
# Signal-to-noise ratios 
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_2(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

#Simulation
for (j in 1:length(snr.vec)){
    SNR = snr.vec[j]
    for (i in 1:n_sim){
        df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df 
        res_lasso = cv.lasso(data=df, beta=beta)
        retention_lasso[i, j] = res_lasso$retention   
        identification_lasso[i, j] = res_lasso$identification
        prediction_lasso[i, j] = res_lasso$mse
        
        res_lasso2 = cv.lasso_2(data=df, beta=beta)
        retention_lasso2[i, j] = res_lasso2$retention   
        identification_lasso2[i, j] = res_lasso2$identification
        prediction_lasso2[i, j] = res_lasso2$mse
        
        res_RF = RF_VSURF(data=df, beta=beta)
        retention_RF[i, j] = res_RF$retention   
        identification_RF[i, j] = res_RF$identification
        prediction_RF[i, j] = res_RF$OOB_error
        
    }
}

#Saving results in dataframe
sim1_retention = data.frame(cbind(t(retention_lasso), t(retention_lasso2), t(retention_RF)))
colnames(sim1_retention) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim1_retention,"sim2_retention.csv", row.names = FALSE)

sim1_identification = data.frame(cbind(t(identification_lasso), t(identification_lasso2), t(identification_RF)))
colnames(sim1_identification) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim1_identification,"sim2_identification.csv", row.names = FALSE)

sim1_prediction = data.frame(cbind(t(prediction_lasso), t(prediction_lasso2), t(prediction_RF)))
colnames(sim1_prediction) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim1_prediction,"sim2_prediction.csv", row.names = FALSE)

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency - Simulation 2", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), col="red", type="b")

#--------------
# Identification Plot
#---------------
true_sparsity = length(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(identification_lasso, true_sparsity), main="Identification frequency - Simulation 2", col="blue", type="b", ylim=c(80,100))
points(snr.vec, retention_frequency(identification_lasso2, true_sparsity),  col="green", type="b")
points(snr.vec, retention_frequency(identification_RF, true_sparsity),  col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE - Simulation 2", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2),  col="green", type="b")
points(snr.vec, error_rate(prediction_RF), col="red", type="b")

```


```{r}
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency - Simulation 2", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), col="red", type="b")

#--------------
# Identification Plot
#---------------
true_sparsity = length(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(identification_lasso, true_sparsity), main="Identification frequency - Simulation 2", col="blue", type="b", ylim=c(80,100))
points(snr.vec, retention_frequency(identification_lasso2, true_sparsity),  col="green", type="b")
points(snr.vec, retention_frequency(identification_RF, true_sparsity),  col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE - Simulation 2", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2),  col="green", type="b")
points(snr.vec, error_rate(prediction_RF), col="red", type="b")
```



```{r}
#--------------------------------
# Simulation 1 - only LAssos
#--------------------------------

start_time <- Sys.time()

# Number of simulations
n_sim = 100
# Signal-to-noise ratios 
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

#Simulation
for (j in 1:length(snr.vec)){
    SNR = snr.vec[j]
    for (i in 1:n_sim){
        df <- simulate(n=100, p=50, rho=0.05, beta=beta, SNR = SNR)$df 
        res_lasso = cv.lasso(data=df, beta=beta)
        retention_lasso[i, j] = res_lasso$retention   
        identification_lasso[i, j] = res_lasso$nonzero
        prediction_lasso[i, j] = res_lasso$mse
        
        res_lasso2 = cv.lasso_2(data=df, beta=beta)
        retention_lasso2[i, j] = res_lasso2$retention   
        identification_lasso2[i, j] = res_lasso2$nonzero
        prediction_lasso2[i, j] = res_lasso2$mse
        
        #res_RF = RF_VSURF(data=df, beta=beta)
        #retention_RF[i, j] = res_RF$retention   
        #identification_RF[i, j] = res_RF$identification
       # prediction_RF[i, j] = res_RF$OOB_error
        
    }
}



end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")

#--------------
# Nonzero Plot
#---------------

plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0,20))
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b", ylim=c(0,20))
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
```

```{r}
#--------------------------------
# Simulation 3 - beta 3
#--------------------------------

start_time <- Sys.time()

# Number of simulations
n_sim = 15
# Signal-to-noise ratios 
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_3(p=50,s=5, value=0.5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

#Simulation
for (j in 1:length(snr.vec)){
    SNR = snr.vec[j]
    for (i in 1:n_sim){
        df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df 
        res_lasso = cv.lasso(data=df, beta=beta)
        retention_lasso[i, j] = res_lasso$retention   
        identification_lasso[i, j] = res_lasso$identification
        prediction_lasso[i, j] = res_lasso$mse
        
        res_lasso2 = cv.lasso_2(data=df, beta=beta)
        retention_lasso2[i, j] = res_lasso2$retention   
        identification_lasso2[i, j] = res_lasso2$identification
        prediction_lasso2[i, j] = res_lasso2$mse
        
        res_RF = RF_VSURF(data=df, beta=beta)
        retention_RF[i, j] = res_RF$retention   
        identification_RF[i, j] = res_RF$identification
        prediction_RF[i, j] = res_RF$OOB_error
        
    }
}

#Saving results in dataframe
sim3_retention = data.frame(cbind(t(retention_lasso), t(retention_lasso2), t(retention_RF)))
colnames(sim3_retention) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim3_retention,"sim3_retention.csv", row.names = FALSE)

sim3_identification = data.frame(cbind(t(identification_lasso), t(identification_lasso2), t(identification_RF)))
colnames(sim3_identification) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim3_identification,"sim3_identification.csv", row.names = FALSE)

sim3_prediction = data.frame(cbind(t(prediction_lasso), t(prediction_lasso2), t(prediction_RF)))
colnames(sim3_prediction) = c(rep("LASSO1", n_sim), rep("LASSO2", n_sim), rep("RF_pred", n_sim))
write.csv(sim3_prediction,"sim3_prediction.csv", row.names = FALSE)

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")

#--------------
# Identification Plot
#---------------
true_sparsity = length(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(identification_lasso, true_sparsity), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(75,100))
points(snr.vec, retention_frequency(identification_lasso2, true_sparsity), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, retention_frequency(identification_RF, true_sparsity), main="Identification frequency VSURF - prediction", col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
```

```{r}
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")

#--------------
# Identification Plot
#---------------
true_sparsity = length(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(identification_lasso, true_sparsity), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0,20))
points(snr.vec, retention_frequency(identification_lasso2, true_sparsity), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, retention_frequency(identification_RF, true_sparsity), main="Identification frequency VSURF - prediction", col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
```


```{r}
#--------------------------------
# Simulation 1 - trying out nonzero
#--------------------------------

start_time <- Sys.time()

# Number of simulations
n_sim = 15
# Signal-to-noise ratios 
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value

#Simulation
for (j in 1:length(snr.vec)){
    SNR = snr.vec[j]
    for (i in 1:n_sim){
        df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df 
        res_lasso = cv.lasso(data=df, beta=beta)
        retention_lasso[i, j] = res_lasso$retention   
        identification_lasso[i, j] = res_lasso$nonzero
        prediction_lasso[i, j] = res_lasso$mse
        
        res_lasso2 = cv.lasso_2(data=df, beta=beta)
        retention_lasso2[i, j] = res_lasso2$retention   
        identification_lasso2[i, j] = res_lasso2$nonzero
        prediction_lasso2[i, j] = res_lasso2$mse
        
        res_RF = RF_VSURF(data=df, beta=beta)
        retention_RF[i, j] = res_RF$retention   
        identification_RF[i, j] = res_RF$nonzero
        prediction_RF[i, j] = res_RF$OOB_error
        
    }
}



end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")

#--------------
# Nonzero Plot
#---------------

plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")

```


```{r}
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")

#--------------
# Nonzero Plot
#---------------

plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0, 20))
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")

#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
```






```{r}
#--------------------------------
# Simulation 1 - no RF
#--------------------------------

start_time <- Sys.time()

# Number of simulations
n_sim = 10
# Signal-to-noise ratios 
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

counter = 1

#Simulation
for (j in 1:length(snr.vec)){
    SNR = snr.vec[j]
    for (i in 1:n_sim){
        #Simulate the data
        #------------------------------
        df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
        
        ID <- j*10+i-10
        
        #calculate AND store the resuls
        #------------------------------
        #Lasso
        res_lasso = cv.lasso_2(data=df, beta=beta)
        results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)

        counter = counter+1 #increase counter by 1
        
        #Relaxed Lasso
        #------------------------------
        res_lasso = cv.relaxed_lasso(data=df, beta=beta)
        results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
        
        counter = counter+1
        
        
    }
}



end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

results

```


```


```{r}
#-------------
# Analysing why Lasso behaves weirdly for SNR = 6
#-------------

beta = beta_2(p=150,s=5)
#set.seed(456)
sim <- simulate(n=100, p=150, rho=0.9, beta=beta, SNR = 6)
df <- sim$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe

out1=cv.glmnet(x,y,alpha=1, intercep = FALSE)
plot(out1)

out2= cv.glmnet(x,y, relax=TRUE, intercept=FALSE)#lpha=1, intercept= FALSE, relax=TRUE)
plot(out2, se.bands=FALSE)
lasso_coef = predict(out2, type = "coefficients", s = "lambda.min", gamma = "gamma.min")
var_retention(lasso_coef, beta)

mse <- out2$cvm[out2$lambda == out2$lambda.1se]

#coef(out, s=lam)
#plot(out, xvar="lambda")
#cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#plot(cv.out) # Draw plot of training MSE as a function of lambda
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
#
#cat(sim$sigma)
#lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
```




```{r}
getwd()
```

