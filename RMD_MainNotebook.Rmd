---
title: "R Notebook"
output:
  html_notebook: default
  pdf_document: default
---



```{r}
#Installing packages#
#install.packages("parallel")
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.
```{r}
library(MASS) 
library(stats)
library(Matrix)
library(parallel)
library(glmnet) #for LASSO
library(VSURF)#for RF
library(ggplot2) #for plotting
library(dplyr) #for plotting
library(cowplot) #for plotting
```


```{r}
#Import auxiliary functions
source("auxiliary_functions.R", local=FALSE)
```
```{r}
set.seed(456)
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
beta = beta_1(p=100,s=5)
df <- simulate(n=100, p=100, rho=0.5, beta=beta, SNR = 1)$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe

cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
plot(cv.out) # Draw plot of training MSE as a function of lambda
lam = cv.out$lambda.1se # Select more conservative lambda for variable selection


lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
```


```{r}

beta = beta_2(p=50,s=5)
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = 1)$df
result = RF_VSURF(data=df, beta=beta)

```




```{r}
#--------------------------------
# Simulation 1
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim1.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)


```





```{r}
df <- sim1 %>% 
  na_if(Inf) %>%
  group_by(SNR, Method) %>%  
  summarize(Mean_Ret = mean(Retention, na.rm=TRUE),
            Mean_Zero = mean(Nonzero, na.rm=TRUE),
            Mean_Pred = mean(Prediction, na.rm=TRUE))

snr.breaks = round(exp(seq(from=min(log(sim1$SNR)),
                           to=max(log(sim1$SNR)),length=4)),2)

ggplot(data=df, aes(x=SNR, y=Mean_Ret, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Retention") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Zero, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Number nonzero coefficients") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Pred, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Prediction Error") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)
```






```{r}
#--------------------------------
# Simulation 2.a - changing correlation by changing beta
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_2(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim2a.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

#---------------
sim2a <- read.csv("sim2a.csv", header=TRUE)

df <- sim2a %>% 
  na_if(Inf) %>%
  group_by(SNR, Method) %>%  
  summarize(Mean_Ret = mean(Retention, na.rm=TRUE),
            Mean_Zero = mean(Nonzero, na.rm=TRUE),
            Mean_Pred = mean(Prediction, na.rm=TRUE))

snr.breaks = round(exp(seq(from=min(log(sim1$SNR)),
                           to=max(log(sim1$SNR)),length=4)),2)

ggplot(data=df, aes(x=SNR, y=Mean_Ret, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Retention") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Zero, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Number nonzero coefficients") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)


ggplot(data=df, aes(x=SNR, y=Mean_Pred, color=Method)) +
  geom_line(lwd=1) +
  geom_point(pch=19) +
  theme_bw() +
  #facet_grid(rows = vars(Method)) +
  #facet_grid(formula(paste(1,"~",2))) +
  xlab("Signal-to-noise ratio") +
  ylab("Prediction Error") +
  geom_line(aes(x=SNR, y=5), lwd=0.5, linetype=3, color="black") +
  ggtitle("Simulation 1") + 
  scale_x_continuous(trans="log", breaks=snr.breaks)

```






```{r}
#--------------------------------
# Simulation 2b - Changing correlation structure - rho
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim2b.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

sim2b <- read.csv("sim2b.csv", header=TRUE)
plot_simulation_results(sim2b, beta)
```

```{r}
#--------------------------------
# Simulation 3 - Beta type 3 (weak sparsity )
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_3(p=50,s=5, value=0.5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim3.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

sim3 <- read.csv("sim3.csv", header=TRUE)
plot_simulation_results(sim3, beta)

```






```{r}
#--------------------------------
# Simulation 2c_very low correlation
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=6, nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.01, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim2c.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

sim2c <- read.csv("sim2c.csv", header=TRUE)
plot_simulation_results(sim2c, beta)

```





```{r}
#-------------
# Analysing why Lasso behaves weirdly for SNR = 6
#-------------

beta = beta_2(p=150,s=5)
#set.seed(456)
sim <- simulate(n=100, p=150, rho=0.9, beta=beta, SNR = 6)
df <- sim$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe

out1=cv.glmnet(x,y,alpha=1, intercep = FALSE)
plot(out1)

out2= cv.glmnet(x,y, relax=TRUE, intercept=FALSE)#lpha=1, intercept= FALSE, relax=TRUE)
plot(out2, se.bands=FALSE)
lasso_coef = predict(out2, type = "coefficients", s = "lambda.min", gamma = "gamma.min")
var_retention(lasso_coef, beta)

mse <- out2$cvm[out2$lambda == out2$lambda.1se]

#coef(out, s=lam)
#plot(out, xvar="lambda")
#cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#plot(cv.out) # Draw plot of training MSE as a function of lambda
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
#
#cat(sim$sigma)
#lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
```



```{r}
#--------------------------------
# Simulation 2d_very low correlation and saving random state
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=(6+626), nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    sim_seed <- t(.GlobalEnv$.Random.seed)

    df <- simulate(n=100, p=50, rho=0.01, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    

    
    #calculate AND store the resuls
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse, sim_seed)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse, sim_seed)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF(data=df, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$OOB_error, sim_seed)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim2d.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)

sim2d <- read.csv("sim2d.csv", header=TRUE)
plot_simulation_results(sim2d, beta)
```


```{r}
sim2d <- read.csv("sim2d.csv", header=TRUE)
View(sim2d)
```





```{r}
#--------------------------------
# Simulation Experimenting with True MSE
#--------------------------------
set.seed(456)

start_time <- Sys.time()

# Simulation Parameters
#---------------------
n_sim = 100 # Number of simulations
snr.vec = exp(seq(log(0.05),log(6),length=10)) # Signal-to-noise ratios 
beta = beta_1(p=50,s=5) # beta vector

#Container to store results
#---------------------
colnames = c("ID_sim", "SNR", "Method", "Retention", "Nonzero", "Prediction")
results = data.frame(matrix(NaN, ncol=(6), nrow=(n_sim*3*length(snr.vec))))
colnames(results) <- colnames

# Initialize Counter
counter <- 1

#Simulation
for (j in 1:length(snr.vec)){
  SNR = snr.vec[j]
  for (i in 1:n_sim){

    #Simulate the data
    #------------------------------
    df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
    df_test <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
    
    ID <- paste(j,i) #identification touple of simulation
    

    
    #calculate AND store the results
    #------------------------------
    #Lasso
    res_lasso = cv.lasso_2_pred(data=df, test_data = df_test, beta=beta)
    results[counter,] <- c(ID, SNR, "Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Relaxd Lasso
    res_lasso = cv.relaxed_lasso_pred(data=df, test_data = df_test, beta=beta)
    results[counter,] <- c(ID, SNR, "Relaxed Lasso", res_lasso$retention, res_lasso$nonzero, res_lasso$mse)
    
    counter = counter+1 #increase counter by 1
        
    #Random Forest   
    res_RF = RF_VSURF_pred(data=df, test_data = df_test, beta=beta)
    results[counter,] <- c(ID, SNR, "RF", res_RF$retention, res_RF$nonzero, res_RF$mse)
    
    counter = counter+1 #increase counter by 1
    
    #Save results
    #------------------------------
    write.csv(results,"sim_experimenting_test_mse.csv", row.names = FALSE)
    
  }
}

end_time <- Sys.time()

cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)


sim_experimenting_test_mse <- read.csv("sim_experimenting_test_mse.csv", header=TRUE)
plot_simulation_results(sim_experimenting_test_mse, beta)
```



```{r}
results$SNR = as.numeric(results$SNR)
results$Retention = as.numeric(results$Retention)
results$Nonzero = as.numeric(results$Nonzero)
results$Prediction = as.numeric(results$Prediction)

plot_simulation_results(results, beta)
```

```{r}
SNR=6
df <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df
df_test <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df

a <- cv.lasso_2_pred(data=df, test_data = df_test, beta=beta)

a

```

```{r}
df <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df
df_test <- simulate(n=100, p=50, rho=0.9, beta=beta, SNR = SNR)$df

x_train <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y_train <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe
  
x_test <- data.matrix(df_test[,-1]) #explan var, glmnet can't use dataframe
y_test <- data.matrix(df_test[,1]) #dependent var, glmnet can't use dataframe

model <- cv.glmnet(x_train, y_train, alpha=1, intercept=FALSE)
cv.out = cv.glmnet(x_train, y_train, alpha = 0) # Fit ridge regression model on training data
bestlam = cv.out$lambda.min  # Select lamda that minimizes training MSE
bestlam
```


```{r}
cv.lasso_2_pred <- function(data, #data frame - dependent variable first
                       test_data, #data frame - dependent variable first
                       beta # true coefficients
){
  #--------------------------
  # Uses 10 fold CV and uses best prediciton lambda
  # as estimate for variable selection
  # -------------------------
  x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
  y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
  
  x_test <- data.matrix(test_data[,-1]) #explan var, glmnet can't use dataframe
  y_test <- data.matrix(test_data[,1]) #dependent var, glmnet can't use dataframe
  
  cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
  #lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
  lam = cv.out$lambda.min
  
  #---------------------
  # Retention Frequency
  #---------------------
  lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
  retention = var_retention(lasso_coef, beta) #counts significant vars
  identification = var_identification(lasso_coef, beta) #counts all vars
  
  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
  
  #---------------------
  # MSE - test set
  #---------------------
  pred_y = predict(cv.out, newx = x_test)
  mse = (mean(y_test - pred_y)^2)

  #---------------------
  # MSE - CV
  #---------------------
  cv.mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se]
  
  results = list("retention" = retention, "identification" =identification, "mse" = mse, "cv.mse" = cv.mse, "nonzero" = nonzero)
  return(results)
}
```

```{r}
cv.relaxed_lasso_pred <- function(data, #data frame - dependent variable first
                             test_data, #data frame - dependent variable first
                             beta # true coefficients
){
  #--------------------------
  # Uses 10 fold CV and uses lambda
  # and gamma minimizing prediction error
  # for variable selection
  # -------------------------
  x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
  y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
  
  x_test <- data.matrix(test_data[,-1]) #explan var, glmnet can't use dataframe
  y_test <- data.matrix(test_data[,1]) #dependent var, glmnet can't use dataframe
  
  cv.out = cv.glmnet(x, y,intercept=FALSE, relax=TRUE) # Fit lasso model on training data
  
  #---------------------
  # Retention Frequency
  #---------------------
  lasso_coef = predict(cv.out, type = "coefficients", s = "lambda.min", gamma = "gamma.min")#"gamma.min") # Display coefficients using lambda chosen by CV
  retention = var_retention(lasso_coef, beta) #counts significant vars
  identification = var_identification(lasso_coef, beta) #counts all vars
  
  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
  
  #---------------------
  # MSE - test set
  #---------------------
  pred_y = predict(cv.out, newx = x_test)
  mse = (mean(y_test - pred_y)^2)
  
  #---------------------
  # MSE - CV
  #---------------------
  cv.mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se]
  
  results = list("retention" = retention, "identification" =identification, "mse" = mse, "cv.mse" = cv.mse, "nonzero" = nonzero)
  return(results)
}
```


```{r}
RF_VSURF_pred <- function(data, #data frame - dependent variable first
                          test_data, #data frame - dependent variable first
                     beta #true coefficients
){
  #--------------------------
  # Uses VSURF prediction under parallelization and
  # returns number of correctly identified  significant variables.
  # Mytree and ntree are set to default
  # ------------------------- 
  x <- data.matrix(data[,-1])
  y <- data.matrix(data[,1]) 
  
  x_test <- data.matrix(test_data[,-1])
  y_test <- data.matrix(test_data[,1]) 
  
  defaultW <- getOption("warn")  #Turn off warning messages
  options(warn = -1) 
  
  
  #Variable Selection using Random Forest
  model.vsurf <- VSURF(x=x, y=y, parallel = TRUE , ncores= 4)
  
  
  #---------------------
  # Retention Frequency
  #---------------------
  #Create boolian vector of selected coefficients
  loc = model.vsurf$varselect.pred # location of significant coefficients
  estim_var = rep(0, length(beta)) #create zero vector of correct length
  estim_var[loc] = 1 #populate zero vector
  
  retention = var_retention(estim_var, beta) #counts only significant variables
  identification = var_identification(estim_var, beta) #counts all vars
  
  #---------------------
  # Number Nonzero elements
  #--------------------- 
  nonzero = var_nonzero(estim_var, beta) #count nonzero vars
  
  #---------------------
  # MSE
  #---------------------
  pred_y = predict(model.vsurf, newdata = x_test)
  mse = (mean(y_test - pred_y$pred)^2)
  
  options(warn = defaultW) #re-enable warning messages
  
  result = list("retention" = retention, "identification" = identification, "mse" = mse, "nonzero" = nonzero)
  
  return(result)
}
```




