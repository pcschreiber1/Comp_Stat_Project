data()
for (r in 1:num_sim){
set.seed(100 + r)
training_sample <- data_generator(N = N, beta = beta_true) #Drawing test and training sample
test_sample <- data_generator(N = N, beta = beta_true)
#---------------------------------------------------------------
X_power_training <- matrix(NaN,N,5) #Generating new variables
X_power_test <- matrix(NaN,N,5)
for (i in 1:5){
X_power_training[,i] <- training_sample[,2]^i
X_power_test[,i] <- test_sample[,2]^i
}
data_power_training <- data.frame("Y" = training_sample[,1], X_power_training)
data_power_test <- data.frame("Y"=test_sample[,1], X_power_test)
#---------------------------------------------------------------
#Fitting models for polynomials with different degrees
MSE_result <- c(NaN)
pred_error_result <- c(NaN)
l_model <- lm(Y ~ 1, data = data_power_training) #special case
MSE_result[1] <- mse(lm = l_model)
pred_error_result[1] <- mean((data_power_test[,1] - coef(l_model))^2)
for (k in 1:5){
l_model <- lm(data_power_training[,1] ~ X_power_training[,1:k])
MSE_result[k+1] <- mse(lm = l_model) #k+1 due to constant case
pred_error_result[k+1] <- a_pred_error(data_test = data_power_test[,1:(k+1)], #k+1 due Y-variable
beta_hat = coef(l_model),
N = N)
}
result_MSE[r] <- MSE_result #storing the results
result_pred[r] <- pred_error_result
}
df <- simulate()
simulate()
f(10)
# Imports
library(MASS)
# Generating Sample
f <- function(x) {
+ x <- x+1
+ return(x^2)
+ }
f(10)
f <- function(x) {
+ x <- x+1
+ return(x^2)
+ }
x <- 3
f(x)
# Generating Sample
f <- function(x){
+ x <- x+1
+ return(x^2)
+ }
# Generating Sample
f <- function(x){
+ x <- x+1
+ return(x^2)}
x <- 3
f(x)
# Generating Sample
f <- function(x){
x <- x+1
return(x^2)}
x <- 3
f(x)
# This module contains auxiliary functions for XY
# which are used in the main notebook.
# --------------------------------------------------------
# Imports
library(MASS)
# Generating Sample
simulate <- function(n1 = 300,
mu1 = c(-3,3),
cov1 = matrix(c(16,-2, -2, 9), nrow=2, ncol=2),
n2 = 500,
mu2 = c(5,5),
cov2 = matrix(c(16,-2, -2, 9), nrow=2, ncol=2)
){
#-------Random Sample
X1 <- mvrnorm(n1, mu1, cov1)
X2 <- mvrnorm(n2, mu2, cov2)
#-------Vector of indicator variables of class dependence
Class <- c(rep(1,n1), rep(2,n2))
#-------Creating data frame
df <- data.frame(Class, rbind(X1, X2))
colnames(df) <- c("Class", "X1", "X2")
df$Class <- factor(df$Class) #for categorical variable
return(df)
}
df <- simulate()
# Generating Sample
simulate <- function(n, #number of observations
p, #number of covariates
rho, #degree of covariance
beta, #vetctor of true coefficients
var_error #variance of the errors
){
if (length(beta) != p){
cat("Number of beta coefficient unequal to p")
}else{
#Mean of explanatory variables
mu = rep(0,p) #all covariates are standardized with mean zero
#Variance-Covariance Matrix
###Note: Matrix only depends on p and rho
toep = rho^(0:(p-1)) #creates geometric series starting at one
sigma = toeplitz(toep) #creates toeplitz matrix from geometric series: rho^(i-j)
X = mvrnorm(n, mu, sigma)
epsilon = rnorm(n, 0, var_error)
Y = X %*% beta + epsilon
#-------Creating data frame
df <- data.frame(Y, X)
return(df)
}
}
df <- simulate(n=10, p=100, rho=0.5, beta=beta, var_error = 1)
beta = c(1,1,1, rep(0, 97))
df <- simulate(n=10, p=100, rho=0.5, beta=beta, var_error = 1)
# This module contains auxiliary functions for XY
# which are used in the main notebook.
# --------------------------------------------------------
# Imports
library(MASS)
library(stats)
# Generating Sample
simulate <- function(n, #number of observations
p, #number of covariates
rho, #degree of covariance
beta, #vetctor of true coefficients
var_error #variance of the errors
){
if (length(beta) != p){
cat("Number of beta coefficient unequal to p")
}else{
#Mean of explanatory variables
mu = rep(0,p) #all covariates are standardized with mean zero
#Variance-Covariance Matrix
###Note: Matrix only depends on p and rho
toep = rho^(0:(p-1)) #creates geometric series starting at one
sigma = toeplitz(toep) #creates toeplitz matrix from geometric series: rho^(i-j)
X = mvrnorm(n, mu, sigma)
epsilon = rnorm(n, 0, var_error)
Y = X %*% beta + epsilon
#-------Creating data frame
df <- data.frame(Y, X)
return(df)
}
}
beta = c(1,1,1, rep(0, 97))
df <- simulate(n=10, p=100, rho=0.5, beta=beta, var_error = 1)
View(df)
library(MASS)
library(stats)
library(Matrix)
library(parallel)
library(glmnet) #for LASSO
library(VSURF)#for RF
