#-------------
beta = beta_2(p=50,s=5)
#set.seed(456)
sim <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = 9)
df <- sim$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe
out1=cv.glmnet(x,y,alpha=1, intercep = FALSE)
plot(out1)
out2= cv.glmnet(x,y, relax=TRUE, intercept=FALSE)#lpha=1, intercept= FALSE, relax=TRUE)
plot(out2, se.bands=FALSE)
lasso_coef = predict(out2, type = "coefficients", s = "lambda.min", gamma = "gamma.min")
mse <- out2$cvm[out2$lambda == out2$lambda.1se]
#coef(out, s=lam)
#plot(out, xvar="lambda")
#cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#plot(cv.out) # Draw plot of training MSE as a function of lambda
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
#
#cat(sim$sigma)
#lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
#-------------
# Analysing why Lasso behaves weirdly for SNR = 6
#-------------
beta = beta_2(p=50,s=5)
#set.seed(456)
sim <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = 90)
df <- sim$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe
out1=cv.glmnet(x,y,alpha=1, intercep = FALSE)
plot(out1)
out2= cv.glmnet(x,y, relax=TRUE, intercept=FALSE)#lpha=1, intercept= FALSE, relax=TRUE)
plot(out2, se.bands=FALSE)
lasso_coef = predict(out2, type = "coefficients", s = "lambda.min", gamma = "gamma.min")
mse <- out2$cvm[out2$lambda == out2$lambda.1se]
#coef(out, s=lam)
#plot(out, xvar="lambda")
#cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#plot(cv.out) # Draw plot of training MSE as a function of lambda
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
#
#cat(sim$sigma)
#lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
cv.relaxed_lasso <- function(data, #data frame - dependent variable first
beta # true coefficients
){
#--------------------------
# Uses 10 fold CV and uses lambda
# and gamma minimizing prediction error
# for variable selection
# -------------------------
x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
cv.out = cv.glmnet(x, y,intercept=FALSE, relaxed=TRUE) # Fit lasso model on training data
#---------------------
# Retention Frequency
#---------------------
lasso_coef = predict(cv.out, type = "coefficients", s = "lambda.min", gamma = "gamma.min") # Display coefficients using lambda chosen by CV
retention = var_retention(lasso_coef, beta) #counts significant vars
identification = var_identification(lasso_coef, beta) #counts all vars
#---------------------
# Number Nonzero elements
#---------------------
nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
#---------------------
# MSE
#---------------------
mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se] # which gamma value is this?
results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
return(results)
}
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
library(ggplot2)
data <- read.csv(sim1, header=TRUE)
View(data)
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
end_time <- Sys.time()
cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")
#--------------
# Nonzero Plot
#---------------
plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")
#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
install.packages("ggplot2")
#install.packages("ggplot2")
library(ggplot2)
data <- read.csv(sim1, header=TRUE)
View(data)
data <- read.csv("sim1.csv", header=TRUE)
getwd()
getwd()
setwd("C:/Users/phili/Documents/GitHub/Comp_Stat_Project")
data <- read.csv("sim1.csv", header=TRUE)
View(data)
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
end_time <- Sys.time()
cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")
#--------------
# Nonzero Plot
#---------------
plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0,50))
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")
#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso2(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso_2(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
end_time <- Sys.time()
cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")
#--------------
# Nonzero Plot
#---------------
plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0,50))
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")
#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
#-------------
# Analysing why Lasso behaves weirdly for SNR = 6
#-------------
beta = beta_2(p=50,s=5)
#set.seed(456)
sim <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = 90)
df <- sim$df
x <- data.matrix(df[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(df[,1]) #dependent var, glmnet can't use dataframe
out1=cv.glmnet(x,y,alpha=1, intercep = FALSE)
plot(out1)
out2= cv.glmnet(x,y, relax=TRUE, intercept=FALSE)#lpha=1, intercept= FALSE, relax=TRUE)
plot(out2, se.bands=FALSE)
lasso_coef = predict(out2, type = "coefficients", s = "lambda.min", gamma = 0)
mse <- out2$cvm[out2$lambda == out2$lambda.1se]
#coef(out, s=lam)
#plot(out, xvar="lambda")
#cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#plot(cv.out) # Draw plot of training MSE as a function of lambda
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
#
#cat(sim$sigma)
#lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
cv.relaxed_lasso <- function(data, #data frame - dependent variable first
beta # true coefficients
){
#--------------------------
# Uses 10 fold CV and uses lambda
# and gamma minimizing prediction error
# for variable selection
# -------------------------
x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
cv.out = cv.glmnet(x, y,intercept=FALSE, relaxed=TRUE) # Fit lasso model on training data
#---------------------
# Retention Frequency
#---------------------
lasso_coef = predict(cv.out, type = "coefficients", s = "lambda.min", gamma = 0)#"gamma.min") # Display coefficients using lambda chosen by CV
retention = var_retention(lasso_coef, beta) #counts significant vars
identification = var_identification(lasso_coef, beta) #counts all vars
#---------------------
# Number Nonzero elements
#---------------------
nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
#---------------------
# MSE
#---------------------
mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se] # which gamma value is this?
results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
return(results)
}
#--------------------------------
# Simulation 1 - no RF
#--------------------------------
start_time <- Sys.time()
# Number of simulations
n_sim = 100
# Signal-to-noise ratios
snr.vec = exp(seq(log(0.05),log(6),length=10))
#beta vector
beta = beta_1(p=50,s=5)
#containers to store results
retention_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
retention_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
identification_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_lasso2 = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
prediction_RF = matrix(NaN, ncol=length(snr.vec), nrow=n_sim) # each column corresponds to SNR value
#Simulation
for (j in 1:length(snr.vec)){
SNR = snr.vec[j]
for (i in 1:n_sim){
df <- simulate(n=100, p=50, rho=0.5, beta=beta, SNR = SNR)$df
res_lasso = cv.lasso_2(data=df, beta=beta)
retention_lasso[i, j] = res_lasso$retention
identification_lasso[i, j] = res_lasso$nonzero
prediction_lasso[i, j] = res_lasso$mse
res_lasso2 = cv.relaxed_lasso(data=df, beta=beta)
retention_lasso2[i, j] = res_lasso2$retention
identification_lasso2[i, j] = res_lasso2$nonzero
prediction_lasso2[i, j] = res_lasso2$mse
#res_RF = RF_VSURF(data=df, beta=beta)
#retention_RF[i, j] = res_RF$retention
#identification_RF[i, j] = res_RF$nonzero
#prediction_RF[i, j] = res_RF$OOB_error
}
}
end_time <- Sys.time()
cat("Duration for Number of Sims = ", n_sim, "is: ", end_time - start_time)
#--------------
# Retention Plot
#---------------
true_sparsity = sum(beta)# SUM as sparsity measure not correct if true beta not binary
plot(snr.vec, retention_frequency(retention_lasso, true_sparsity), main="Retention frequency lasso - conservative", col="blue", type = "b")
lines(snr.vec, retention_frequency(retention_lasso2, true_sparsity), main="Retention frequency lasso - optimal pred", col="green", type="b")
lines(snr.vec, retention_frequency(retention_RF, true_sparsity), main="Retention frequency VSURF - prediction", col="red", type="b")
#--------------
# Nonzero Plot
#---------------
plot(snr.vec, error_rate(identification_lasso), main="Identification frequency lasso - conservative", col="blue", type="b", ylim=c(0,50))
points(snr.vec, error_rate(identification_lasso2), main="Identification frequency lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(identification_RF), main="Identification frequency VSURF - prediction", col = "red", type="b")
#--------------
# Prediction Plot
#---------------
plot(snr.vec, error_rate(prediction_lasso), main="MSE lasso - conservative", col="blue", type="b")
points(snr.vec, error_rate(prediction_lasso2), main="MSE lasso - optimal pred", col="green", type="b")
points(snr.vec, error_rate(prediction_RF), main="MSE VSURF - prediction", col="red", type="b")
cv.lasso_2 <- function(data, #data frame - dependent variable first
beta # true coefficients
){
#--------------------------
# Uses 10 fold CV and uses best prediciton lambda
# as estimate for variable selection
# -------------------------
x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
cv.out = cv.glmnet(x, y, alpha = 1, intercept=FALSE) # Fit lasso model on training data
#lam = cv.out$lambda.1se # Select more conservative lambda for variable selection
lam = cv.out$lambda.min
#---------------------
# Retention Frequency
#---------------------
lasso_coef = predict(cv.out, type = "coefficients", s = lam) # Display coefficients using lambda chosen by CV
retention = var_retention(lasso_coef, beta) #counts significant vars
identification = var_identification(lasso_coef, beta) #counts all vars
#---------------------
# Number Nonzero elements
#---------------------
nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
#---------------------
# MSE
#---------------------
mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se]
results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
return(results)
}
cv.relaxed_lasso <- function(data, #data frame - dependent variable first
beta # true coefficients
){
#--------------------------
# Uses 10 fold CV and uses lambda
# and gamma minimizing prediction error
# for variable selection
# -------------------------
x <- data.matrix(data[,-1]) #explan var, glmnet can't use dataframe
y <- data.matrix(data[,1]) #dependent var, glmnet can't use dataframe
cv.out = cv.glmnet(x, y,intercept=FALSE, relaxed=TRUE) # Fit lasso model on training data
#---------------------
# Retention Frequency
#---------------------
lasso_coef = predict(cv.out, type = "coefficients", s = "lambda.min", gamma = 1)#"gamma.min") # Display coefficients using lambda chosen by CV
retention = var_retention(lasso_coef, beta) #counts significant vars
identification = var_identification(lasso_coef, beta) #counts all vars
#---------------------
# Number Nonzero elements
#---------------------
nonzero = var_nonzero(lasso_coef, beta) #count nonzero vars
#---------------------
# MSE
#---------------------
mse <- cv.out$cvm[cv.out$lambda == cv.out$lambda.1se] # which gamma value is this?
results = list("retention" = retention, "identification" =identification, "mse" = mse, "nonzero" = nonzero)
return(results)
}
